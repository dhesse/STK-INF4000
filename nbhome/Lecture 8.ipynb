{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Cover Type Data Set\n",
    "\n",
    "You can download it here:\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Covertype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names for the data, c.f. the description for details.\n",
    "# One important thing to note is that some of the variables\n",
    "# (e.g. the soil type) are indicator variables. One could have\n",
    "# a discussion about how sensible it is to use LDA with these,\n",
    "# but we'll just proceed for educational value.\n",
    "column_names = (\n",
    "[\"Elevation\",\n",
    "\"Aspect\",\n",
    "\"Slope\",\n",
    "\"Horizontal_Distance_To_Hydrology\",\n",
    "\"Vertical_Distance_To_Hydrology\",\n",
    "\"Horizontal_Distance_To_Roadways\",\n",
    "\"Hillshade_9am\",\n",
    "\"Hillshade_Noon\",\n",
    "\"Hillshade_3pm\",\n",
    "\"Horizontal_Distance_To_Fire_Points\"]\n",
    "    + ['WE{}'.format(i) for i in range(4)]\n",
    "    + ['ST{}'.format(i) for i in range(40)]\n",
    "    + ['Cover'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_data = pd.read_csv('data/covtype.data.gz', names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some variables look somewhat Gaussian, or\n",
    "# at least like on could transform them to\n",
    "# look somwhat Gaussian...\n",
    "cover_data.Elevation.plot.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... while some clearly don't\n",
    "cover_data.WE2.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the priors to make sure that we\n",
    "# don't have a singular, very small class.\n",
    "cover_data.groupby('Cover').Cover.count() / cover_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = cover_data.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting two examplary variables against each other\n",
    "# shows that the classification task is a hard one\n",
    "for k, group in sample.groupby('Cover'):\n",
    "    plt.scatter(group.Elevation, group.Slope, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Linear Discriminant Analysis\n",
    "\n",
    "We now proceed to fit a LDA to our data.\n",
    "\n",
    "$$\\begin{align}\n",
    "\\hat \\pi_l &= \\frac{N_l}{N}\\\\\n",
    "\\hat \\mu_l &= \\frac 1 {N_l} \\sum_{i, g_i = l} x_i\\\\\n",
    "\\hat \\Sigma &= \\frac 1 {N - K} \\sum_l \\sum_{i, g_i = l} (x_i - \\hat \\mu_l)(x_i -\n",
    "  \\hat \\mu_l)^T\\\\\n",
    "\\hat \\Sigma_l &= \\frac 1 {N_l - 1} \\sum_{i,g_i = l}(x_i - \\hat \\mu_l)(x_i -\n",
    "  \\hat \\mu_l)^T\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(cover_data, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: Make sure we have all the classes\n",
    "# in the training data set ...\n",
    "train.groupby('Cover').Cover.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... and in the test data set as well...\n",
    "test.groupby('Cover').Cover.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means, pis, labels, Sigmas = [], [], [], []\n",
    "N, p = train.shape\n",
    "p -= 1\n",
    "Sigma = np.zeros([p, p])\n",
    "for label, data in train.groupby('Cover'):\n",
    "    labels.append(label)\n",
    "    Nk, _ = data.shape\n",
    "    # prior\n",
    "    pi = Nk / float(N)\n",
    "    pis.append(pi)\n",
    "    # mean\n",
    "    mu = data.mean()\n",
    "    # below, XXX[:-1]: Drop the 'Cover' column\n",
    "    means.append(mu[:-1])\n",
    "    xn = (data - mu).values[:,:-1]\n",
    "    # Sigma_k\n",
    "    S = np.zeros([p, p])\n",
    "    for i in range(Nk):\n",
    "        S += np.dot(xn[i:i+1,:].T, xn[i:i+1,:])\n",
    "    Sigmas.append(S / (Nk - 1))\n",
    "    # total Sigma\n",
    "    Sigma += S\n",
    "# normalize Sigma\n",
    "Sigma /= float(N - len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't try this at home.\n",
    "# It's usually a bad idea to invert a matrix!\n",
    "# Recommended reading: https://www.johndcook.com/blog/2010/01/19/dont-invert-that-matrix/\n",
    "Sigmainv = np.linalg.inv(Sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminant functions\n",
    "def delta(x, mu, pi):\n",
    "    return (np.dot(np.dot(x, Sigmainv), mu)\n",
    "            - 0.5 * np.dot(np.dot(mu.T, Sigmainv), mu)\n",
    "            + np.log(pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calssifer\n",
    "def lda(x):\n",
    "    return np.argmax(np.array([delta(x, mu, pi) for mu, pi in zip(means, pis)]).T, axis=1)\n",
    "# Note that lda classifies 0, ..., K-1 ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... but our labels are 1, ..., K\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we need to add 1 to make a prediciton\n",
    "# Let's calcuate the hit rate:\n",
    "# HR = (true positives + true negatives) / N\n",
    "# Note we need column_names[:-1] to drop the 'Cover' column\n",
    "((lda(test[column_names[:-1]]) + 1) == test.Cover).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per-class hit rate:\n",
    "for k, data in test.groupby('Cover'):\n",
    "    print k, (lda(data[column_names[:-1]]) + 1 == data.Cover).mean()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
