{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forst Cover Data\n",
    "\n",
    "http://archive.ics.uci.edu/ml/datasets/Covertype\n",
    "\n",
    "Data Set Information:\n",
    "\n",
    "Predicting forest cover type from cartographic variables only (no remotely sensed data). The actual forest cover type for a given observation (30 x 30 meter cell) was determined from US Forest Service (USFS) Region 2 Resource Information System (RIS) data. Independent variables were derived from data originally obtained from US Geological Survey (USGS) and USFS data. Data is in raw form (not scaled) and contains binary (0 or 1) columns of data for qualitative independent variables (wilderness areas and soil types).\n",
    "\n",
    "This study area includes four wilderness areas located in the Roosevelt National Forest of northern Colorado. These areas represent forests with minimal human-caused disturbances, so that existing forest cover types are more a result of ecological processes rather than forest management practices.\n",
    "\n",
    "Some background information for these four wilderness areas: Neota (area 2) probably has the highest mean elevational value of the 4 wilderness areas. Rawah (area 1) and Comanche Peak (area 3) would have a lower mean elevational value, while Cache la Poudre (area 4) would have the lowest mean elevational value.\n",
    "\n",
    "As for primary major tree species in these areas, Neota would have spruce/fir (type 1), while Rawah and Comanche Peak would probably have lodgepole pine (type 2) as their primary species, followed by spruce/fir and aspen (type 5). Cache la Poudre would tend to have Ponderosa pine (type 3), Douglas-fir (type 6), and cottonwood/willow (type 4).\n",
    "\n",
    "The Rawah and Comanche Peak areas would tend to be more typical of the overall dataset than either the Neota or Cache la Poudre, due to their assortment of tree species and range of predictive variable values (elevation, etc.) Cache la Poudre would probably be more unique than the others, due to its relatively low elevation range and species composition.\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "Given is the attribute name, attribute type, the measurement unit and a brief description. The forest cover type is the classification problem. The order of this listing corresponds to the order of numerals along the rows of the database.\n",
    "\n",
    "Name / Data Type / Measurement / Description\n",
    "\n",
    "Elevation / quantitative /meters / Elevation in meters\n",
    "Aspect / quantitative / azimuth / Aspect in degrees azimuth\n",
    "Slope / quantitative / degrees / Slope in degrees\n",
    "Horizontal_Distance_To_Hydrology / quantitative / meters / Horz Dist to nearest surface water features\n",
    "Vertical_Distance_To_Hydrology / quantitative / meters / Vert Dist to nearest surface water features\n",
    "Horizontal_Distance_To_Roadways / quantitative / meters / Horz Dist to nearest roadway\n",
    "Hillshade_9am / quantitative / 0 to 255 index / Hillshade index at 9am, summer solstice\n",
    "Hillshade_Noon / quantitative / 0 to 255 index / Hillshade index at noon, summer soltice\n",
    "Hillshade_3pm / quantitative / 0 to 255 index / Hillshade index at 3pm, summer solstice\n",
    "Horizontal_Distance_To_Fire_Points / quantitative / meters / Horz Dist to nearest wildfire ignition points\n",
    "Wilderness_Area (4 binary columns) / qualitative / 0 (absence) or 1 (presence) / Wilderness area designation\n",
    "Soil_Type (40 binary columns) / qualitative / 0 (absence) or 1 (presence) / Soil Type designation\n",
    "Cover_Type (7 types) / integer / 1 to 7 / Forest Cover Type designation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = (\n",
    "[\"Elevation\",\n",
    "\"Aspect\",\n",
    "\"Slope\",\n",
    "\"Horizontal_Distance_To_Hydrology\",\n",
    "\"Vertical_Distance_To_Hydrology\",\n",
    "\"Horizontal_Distance_To_Roadways\",\n",
    "\"Hillshade_9am\",\n",
    "\"Hillshade_Noon\",\n",
    "\"Hillshade_3pm\",\n",
    "\"Horizontal_Distance_To_Fire_Points\"]\n",
    "    + ['WE{}'.format(i) for i in range(4)]\n",
    "    + ['ST{}'.format(i) for i in range(40)]\n",
    "    + ['Cover'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_data = pd.read_csv('data/covtype.data.gz', names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_data.Elevation.plot.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_data.WE2.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_data.groupby('Cover').Cover.count() / cover_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = cover_data.sample(10000)\n",
    "for k, group in sample.groupby('Cover'):\n",
    "    plt.scatter(group.Elevation, group.Slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(cover_data, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means, pis, labels, Sigmas = [], [], [], []\n",
    "N, p = train.shape\n",
    "p -= 1\n",
    "Sigma = np.zeros([p, p])\n",
    "for label, data in train.groupby('Cover'):\n",
    "    labels.append(label)\n",
    "    Nk, _ = data.shape\n",
    "    print Nk, N, label\n",
    "    pis.append(Nk / float(N))\n",
    "    mu = data.mean()\n",
    "    means.append(mu[:-1])\n",
    "    xn = (data - mu).values[:,:-1]\n",
    "    S = np.zeros([p, p])\n",
    "    for i in range(Nk):\n",
    "        S += np.dot(xn[i:i+1,:].T, xn[i:i+1,:])\n",
    "    Sigmas.append(S / (Nk - 1))\n",
    "    Sigma += S\n",
    "Sigma /= float(N - len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigmainv = np.linalg.inv(Sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta(x, mu, pi):\n",
    "    return (np.dot(np.dot(x, Sigmainv), mu)\n",
    "            - 0.5 * np.dot(np.dot(mu.T, Sigmainv), mu)\n",
    "            + np.log(pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda(x):\n",
    "    return np.argmax(np.array([delta(x, mu, pi) for mu, pi in zip(means, pis)]).T, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(lda(test[column_names[:-1]]) + 1 == test.Cover).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l, X in test.groupby('Cover'):\n",
    "    print l, (lda(X[column_names[:-1]]) + 1 == l).mean(), float(len(X)) / len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Si = np.linalg.inv(0.5*Sigmas[0] + 0.5*Sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_r(x, mu, pi, logS, Sinv):\n",
    "    return (-0.5 * logS\n",
    "            - 0.5 * np.sum(np.dot((x-mu), Sinv) * (x-mu), axis=1)\n",
    "            + np.log(pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rda(x, alpha):\n",
    "    Sigmas_r = [alpha*S + (1-alpha)*Sigma for S in Sigmas]\n",
    "    eigs = [np.linalg.eig(S)[0] for S in Sigmas_r]\n",
    "    logs = [np.sum(np.log(e[e>1e-12])) for e in eigs]\n",
    "    Sinv_r = [np.linalg.inv(S) for S in Sigmas_r]\n",
    "    vals = np.array([delta_r(x, mu, pi, logS, Sinv) for mu, pi, Sinv, logS \n",
    "                               in zip(means, pis, Sinv_r, logs)]).T\n",
    "    return np.argmax(vals, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(rda(test[column_names[:-1]], 0) + 1 == test.Cover).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(rda(test[column_names[:-1]], 0.8) + 1 == test.Cover).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l, X in test.groupby('Cover'):\n",
    "    print l, (rda(X[column_names[:-1]], 0.2) + 1 == l).mean(), float(len(X)) / len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l, X in test.groupby('Cover'):\n",
    "    print l, (rda(X[column_names[:-1]], 0.8) + 1 == l).mean(), float(len(X)) / len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = np.arange(0.1, 1, 0.1)\n",
    "hits = [(rda(test[column_names[:-1]], r) + 1 == test.Cover).mean() for r in rs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rs, hits)\n",
    "plt.xlabel(r'$\\alpha$')\n",
    "plt.ylabel('hit rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_model = LinearDiscriminantAnalysis().fit(train[column_names[:-1]], train.Cover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_hits = sk_model.predict(test[column_names[:-1]]) == test.Cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_hits.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas = []\n",
    "Ns = np.arange(1e4, 6e4, 1e4)\n",
    "for N in Ns:\n",
    "    X = train.sample(int(N))\n",
    "    start = time.time()\n",
    "    lr = LogisticRegression().fit(X[column_names[:-1]], X.Cover)\n",
    "    deltas.append(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltasLDA = []\n",
    "for N in Ns:\n",
    "    X = train.sample(int(N))\n",
    "    start = time.time()\n",
    "    lda = LinearDiscriminantAnalysis().fit(X[column_names[:-1]], X.Cover)\n",
    "    deltasLDA.append(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Ns, deltas)\n",
    "plt.plot(Ns, deltasLDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
