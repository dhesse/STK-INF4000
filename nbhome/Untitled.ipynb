{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array([[1], [2], [3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.array([1,2,3]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [2, 4, 6],\n",
       "       [3, 6, 9]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.array([1,2,3]).reshape(-1,1), np.array([1,2,3]).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=PySparkShell, master=local[*]) created by <module> at /Users/dirk/Virtualenvs/std/lib/python2.7/site-packages/IPython/utils/py3compat.py:289 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4443dd5159b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/dirk/opt/spark-2.1.0-bin-hadoop2.7/python/pyspark/context.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \"\"\"\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callsite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_spark_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mCallSite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m/Users/dirk/opt/spark-2.1.0-bin-hadoop2.7/python/pyspark/context.pyc\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    270\u001b[0m                         \u001b[0;34m\" created by %s at %s:%s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                         % (currentAppName, currentMaster,\n\u001b[0;32m--> 272\u001b[0;31m                             callsite.function, callsite.file, callsite.linenum))\n\u001b[0m\u001b[1;32m    273\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                     \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=PySparkShell, master=local[*]) created by <module> at /Users/dirk/Virtualenvs/std/lib/python2.7/site-packages/IPython/utils/py3compat.py:289 "
     ]
    }
   ],
   "source": [
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x10ab14790>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mu = [[0, 0], [10, 10]]\n",
    "sigma = [[1, 0], [0, 1]]\n",
    "points = []\n",
    "labels = []\n",
    "for i, m in enumerate(mu):\n",
    "    points.append(np.random.multivariate_normal(m, sigma, 100))\n",
    "    labels += [i]*100\n",
    "points=np.vstack(points)\n",
    "RDD = sc.parallelize([(x, i) for x, i in zip(points, labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<type 'int'>, {0: 100, 1: 100})\n"
     ]
    }
   ],
   "source": [
    "N = RDD.count()\n",
    "Ns = RDD.map(lambda (_, g): (g, None)).countByKey()\n",
    "print Ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pis = {i: Ns[i]/float(N) for i in Ns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5, 1: 0.5}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, array([-8.733856  ,  8.01589336])), (1, array([  995.42987443,  1004.36990818]))]\n"
     ]
    }
   ],
   "source": [
    "mus = RDD.map(lambda (x, g): (g, x)).reduceByKey(add).collect()\n",
    "print mus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mus = {l: mu/Ns[l] for l,mu in mus}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "S = (RDD\n",
    "             .map(lambda (x, l): np.dot((x - mus[l]).reshape(-1,1),\n",
    "                                        (x - mus[l].reshape(1,-1))))\n",
    "             .reduce(add))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.02676682, -0.05683141],\n",
       "       [-0.05683141,  1.01163928]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(S / (200 - 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mu = [[0, 0], [10, 10]]\n",
    "sigma = [[1, 0], [0, 1]]\n",
    "points = []\n",
    "labels = []\n",
    "N = 10000\n",
    "for i, m in enumerate(mu):\n",
    "    points.append(np.random.multivariate_normal(m, sigma, N))\n",
    "    labels += [i]*N\n",
    "points = np.vstack(points)\n",
    "RDD = sc.parallelize([(x, i) for x, i in zip(points, labels)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def LDA(RDD):\n",
    "    '''Given a Spark RDD consisting of pairs (x, g), where x is a\n",
    "    numpy array and g is an integer label, return the priors pi, the\n",
    "    variance-covariance matrix Sigma, and the group means mu for\n",
    "    linear discriminant analysis.\n",
    "\n",
    "    Returns: (pi, Sigma, mu)\n",
    "             where pi, mu are dictionaries containing the priors and\n",
    "             centers for each class.\n",
    "\n",
    "    Example:\n",
    "    >>> mu = [[0, 0], [10, 10]]\n",
    "    >>> sigma = [[1, 0], [0, 1]]\n",
    "    >>> points = []\n",
    "    >>> labels = []\n",
    "    >>> N = 10000\n",
    "    >>> for i, m in enumerate(mu):\n",
    "    ...     points.append(np.random.multivariate_normal(m, sigma, N))\n",
    "    ...     labels += [i]*N\n",
    "    ...\n",
    "    >>> points = np.vstack(points)\n",
    "    >>> RDD = sc.parallelize([(x, i) for x, i in zip(points, labels)])\n",
    "    >>> LDA(RDD)\n",
    "    \n",
    "    '''\n",
    "    N = RDD.count()\n",
    "    Ns = RDD.map(lambda (_, g): (g, None)).countByKey()\n",
    "    pis = {i: Ns[i]/float(N) for i in Ns}\n",
    "    sums = RDD.map(lambda (x, g): (g, x)).reduceByKey(add).collect()\n",
    "    mus = {l: s/Ns[l] for l,s in sums}\n",
    "    Sigma = (RDD\n",
    "             .map(lambda (x, l): np.dot((x-mus[l]).reshape(-1,1),\n",
    "                                        (x-mus[l]).reshape(1,-1)))\n",
    "             .reduce(add))\n",
    "    Sigma /= float(N - len(Ns))\n",
    "    \n",
    "    return pis, Sigma, mus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 0.5, 1: 0.5}, array([[ 1.0033927 ,  0.01500472],\n",
       "        [ 0.01500472,  0.9900926 ]]), {0: array([-0.02056332,  0.00299521]),\n",
       "  1: array([  9.99377919,  10.01389058])})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA(RDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pis, Sigma, mus = LDA(RDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5, 1: 0.5}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0033927 ,  0.01500472],\n",
       "       [ 0.01500472,  0.9900926 ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([-0.02056332,  0.00299521]), 1: array([  9.99377919,  10.01389058])}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "response = requests.get('https://en.wikipedia.org/wiki/Representational_state_transfer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date , Sat, 11 Mar 2017 08:48:47 GMT\n",
      "Content-Type , text/html; charset=UTF-8\n",
      "Content-Length , 21753\n",
      "Connection , keep-alive\n",
      "Server , mw1240.eqiad.wmnet\n",
      "Vary , Accept-Encoding,Cookie,Authorization\n",
      "X-Powered-By , HHVM/3.12.14\n",
      "X-UA-Compatible , IE=Edge\n",
      "Content-language , en\n",
      "Content-Encoding , gzip\n",
      "P3P , CP=\"This is not a P3P policy! See https://en.wikipedia.org/wiki/Special:CentralAutoLogin/P3P for more info.\"\n",
      "X-Content-Type-Options , nosniff\n",
      "Last-Modified , Tue, 07 Mar 2017 07:47:29 GMT\n",
      "Backend-Timing , D=83624 t=1488912602973474\n",
      "X-Varnish , 565371581 573348527, 403841898 643614795, 100811527 841270377\n",
      "Via , 1.1 varnish-v4, 1.1 varnish-v4, 1.1 varnish-v4\n",
      "Age , 223120\n",
      "X-Cache , cp1066 hit/2, cp3043 hit/21, cp3043 hit/60\n",
      "X-Cache-Status , hit\n",
      "Strict-Transport-Security , max-age=31536000; includeSubDomains; preload\n",
      "Set-Cookie , WMF-Last-Access=11-Mar-2017;Path=/;HttpOnly;secure;Expires=Wed, 12 Apr 2017 00:00:00 GMT, WMF-Last-Access-Global=11-Mar-2017;Path=/;Domain=.wikipedia.org;HttpOnly;secure;Expires=Wed, 12 Apr 2017 00:00:00 GMT, GeoIP=NO:11:Stavanger:58.97:5.75:v4; Path=/; secure; Domain=.wikipedia.org\n",
      "X-Analytics , ns=0;page_id=907222;https=1;nocookies=1\n",
      "X-Client-IP , 80.86.214.114\n",
      "Cache-Control , private, s-maxage=0, max-age=0, must-revalidate\n",
      "Accept-Ranges , bytes\n"
     ]
    }
   ],
   "source": [
    "for k in response.headers:\n",
    "    print k, ',', response.headers[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
